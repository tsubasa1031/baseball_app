import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import joblib
from pybaseball import statcast
import warnings
import os

# è­¦å‘Šã‚’ç„¡è¦–
warnings.filterwarnings('ignore')

def fetch_real_data(start_dt, end_dt):
    print(f"âš¾ MLBå…¬å¼ãƒ‡ãƒ¼ã‚¿(Statcast)ã‚’å–å¾—ä¸­... (æœŸé–“: {start_dt} - {end_dt})")
    # ãƒ‡ãƒ¼ã‚¿é‡ã‚’å‰Šæ¸›ã™ã‚‹ãŸã‚ã€æœŸé–“ã‚’æŒ‡å®šã—ã¦å–å¾—
    df = statcast(start_dt=start_dt, end_dt=end_dt)
    print(f"âœ… å–å¾—å®Œäº†: {len(df)} çƒã®ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºä¿ã—ã¾ã—ãŸã€‚")
    return df

def preprocess_data(df):
    print("âš™ï¸ ãƒ‡ãƒ¼ã‚¿ã‚’å­¦ç¿’ç”¨ã«åŠ å·¥ä¸­...")
    
    # 1. å‹æ•—çµæœã®ä½œæˆ
    game_results = df.groupby('game_pk').agg({
        'home_score': 'max',
        'away_score': 'max'
    }).reset_index()
    
    game_results['home_win_flag'] = (game_results['home_score'] > game_results['away_score']).astype(int)
    df = df.merge(game_results[['game_pk', 'home_win_flag']], on='game_pk', how='left')
    
    # 2. åŸºæœ¬ç‰¹å¾´é‡ã®ä½œæˆ
    df['score_diff'] = df['home_score'] - df['away_score']
    df['is_top'] = (df['inning_topbot'] == 'Top').astype(int)
    df['on_1b'] = df['on_1b'].notnull().astype(int)
    df['on_2b'] = df['on_2b'].notnull().astype(int)
    df['on_3b'] = df['on_3b'].notnull().astype(int)

    # 3. é¸æ‰‹æˆç¸¾ï¼ˆOPSï¼‰ã®è¨ˆç®—
    print("   æ‰“è€…ãƒ»æŠ•æ‰‹ã®æˆç¸¾ã‚’é›†è¨ˆä¸­...")

    def calculate_ops_simple(group):
        events = group['events']
        hits = events.isin(['single', 'double', 'triple', 'home_run']).sum()
        ab = (~events.isin(['walk', 'hit_by_pitch', 'sac_fly', 'sac_bunt', 'intent_walk'])).sum()
        walks = events.isin(['walk', 'hit_by_pitch', 'intent_walk']).sum()
        tb = (events == 'single').sum() * 1 + (events == 'double').sum() * 2 + \
             (events == 'triple').sum() * 3 + (events == 'home_run').sum() * 4
        
        obp = (hits + walks) / (ab + walks) if (ab + walks) > 0 else 0.3
        slg = tb / ab if ab > 0 else 0.4
        return obp + slg

    try:
        batter_ops = df.groupby('batter').apply(calculate_ops_simple).to_dict()
        pitcher_ops = df.groupby('pitcher').apply(calculate_ops_simple).to_dict()
        df['batter_ops'] = df['batter'].map(batter_ops).fillna(0.720)
        df['pitcher_opp_ops'] = df['pitcher'].map(pitcher_ops).fillna(0.720)
    except:
        df['batter_ops'] = 0.720
        df['pitcher_opp_ops'] = 0.720

    feature_cols = [
        'score_diff', 'inning', 'is_top', 'outs_when_up', 
        'on_1b', 'on_2b', 'on_3b',
        'batter_ops', 'pitcher_opp_ops'
    ]
    target_col = 'home_win_flag'
    
    df_clean = df[feature_cols + [target_col]].dropna()
    
    return df_clean[feature_cols], df_clean[target_col]

def save_model_split(model, filename, chunk_size=20 * 1024 * 1024): 
    """ 
    ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã€æŒ‡å®šã‚µã‚¤ã‚º(ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ20MB)ã‚’è¶…ãˆãŸã‚‰åˆ†å‰²ã™ã‚‹ 
    """
    temp_name = f"temp_model.pkl"
    print(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ã‚’ä¸€æ™‚ä¿å­˜ä¸­...")
    joblib.dump(model, temp_name, compress=3)
    
    file_size = os.path.getsize(temp_name)
    print(f"ğŸ“¦ ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º: {file_size / (1024*1024):.2f} MB")

    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
    directory = os.path.dirname(filename)
    if directory and not os.path.exists(directory):
        os.makedirs(directory)
        print(f"ğŸ“ ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ: {directory}")

    # åˆ†å‰²ä¸è¦ãªå ´åˆ (chunk_sizeä»¥ä¸‹)
    if file_size <= chunk_size:
        if os.path.exists(filename):
            os.remove(filename)
        os.rename(temp_name, filename)
        print(f"ğŸ‰ åˆ†å‰²ä¸è¦ã§ã™ã€‚ '{filename}' ã¨ã—ã¦ä¿å­˜ã—ã¾ã—ãŸã€‚")
        return

    # åˆ†å‰²å‡¦ç†
    print(f"âœ‚ï¸ ã‚µã‚¤ã‚ºãŒå¤§ãã„ã®ã§ {chunk_size / (1024*1024):.0f}MB ã”ã¨ã«åˆ†å‰²ã—ã¾ã™...")
    part_num = 0
    with open(temp_name, "rb") as f:
        while True:
            chunk = f.read(chunk_size)
            if not chunk:
                break
            part_name = f"{filename}.part{part_num}"
            with open(part_name, "wb") as part_file:
                part_file.write(chunk)
            print(f"  -> {part_name} ä¿å­˜å®Œäº†")
            part_num += 1
            
    os.remove(temp_name) # å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã¯å‰Šé™¤
    print("âœ… åˆ†å‰²ä¿å­˜å®Œäº†ï¼Gitã«ã¯ã“ã‚Œã‚‰ã® .part ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

def create_and_save_model():
    # å–å¾—æœŸé–“ã®è¨­å®š
    start_dt = '2025-01-01'
    end_dt = '2025-12-31'

    try:
        raw_df = fetch_real_data(start_dt, end_dt)
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return

    X, y = preprocess_data(raw_df)
    
    if len(X) == 0:
        print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã—ãŸã€‚æœŸé–“ã‚’å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚")
        return

    print(f"ğŸ“Š å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•°: {len(X)} ä»¶")
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    print("ğŸ§  AIãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­... (max_depth=30)")
    clf = RandomForestClassifier(n_estimators=50, max_depth=30, random_state=42, n_jobs=-1)
    clf.fit(X_train, y_train)
    
    y_pred = clf.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"âœ… å­¦ç¿’å®Œäº†! ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®æ­£è§£ç‡: {acc:.1%}")
    
    # ä¿å­˜å…ˆã®è¨­å®š: baseball_modelãƒ•ã‚©ãƒ«ãƒ€ã®ä¸­ã«æ—¥ä»˜ä»˜ãã§ä¿å­˜
    save_folder = 'baseball_model'
    save_filename = os.path.join(save_folder, f'baseball_model({start_dt}ãƒ¼{end_dt}).pkl')
    
    # åˆ†å‰²ä¿å­˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨
    save_model_split(clf, save_filename)

if __name__ == "__main__":
    create_and_save_model()